{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Functions\n",
    "def accuracy(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection)/union\n",
    "\n",
    "def precision(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    return float(intersection)/len(list1)\n",
    "\n",
    "def recall(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    return float(intersection)/len(list2)\n",
    "\n",
    "def f1(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    precision_score = precision(list1, list2)\n",
    "    recall_score = recall(list1, list2)\n",
    "    try:\n",
    "        f1_score = float(2*precision_score*recall_score)/(precision_score+recall_score)\n",
    "    except:\n",
    "        f1_score = 0\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df: pd.DataFrame):\n",
    "    all_accuracies = []\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_f1 = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        true_labels = ast.literal_eval(row[\"True Labels\"])\n",
    "        pred_labels = ast.literal_eval(row[\"Predicted Labels\"])\n",
    "\n",
    "        accuracy_score = accuracy(pred_labels, true_labels)\n",
    "        precision_score = precision(pred_labels, true_labels)\n",
    "        recall_score = recall(pred_labels, true_labels)\n",
    "        f1_score = f1(pred_labels, true_labels)\n",
    "\n",
    "        all_accuracies.append(accuracy_score)\n",
    "        all_precision.append(precision_score)\n",
    "        all_recall.append(recall_score)\n",
    "        all_f1.append(f1_score)\n",
    "\n",
    "\n",
    "    avg_acc = sum(all_accuracies)/len(all_accuracies)\n",
    "    avg_prec = sum(all_precision)/len(all_precision)\n",
    "    avg_rec = sum(all_recall)/len(all_recall)\n",
    "    avg_f1 = sum(all_f1)/len(all_f1)\n",
    "\n",
    "    print(\"Average Accuracy on Test Data:\", round(avg_acc*100,2), \"%\")\n",
    "    print(\"Average Precision on Test Data:\", round(avg_prec*100,2), \"%\")\n",
    "    print(\"Average Recall on Test Data:\", round(avg_rec*100,2), \"%\")\n",
    "    print(\"Average F1-Score on Test Data:\", round(avg_f1*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"predictedLabelsFewShotNoTuning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power Plant</th>\n",
       "      <th>Sentence/Paragraph</th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>True Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diablo Canyon</td>\n",
       "      <td>Personnel error (cognitive) by a utility licen...</td>\n",
       "      <td>['personal accountability', 'work processes']</td>\n",
       "      <td>['decision making', 'personal accountability',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diablo Canyon</td>\n",
       "      <td>The cause of the events was human error enable...</td>\n",
       "      <td>['continuous learning', 'personal accountabili...</td>\n",
       "      <td>['leadership safety values and actions', 'pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diablo Canyon</td>\n",
       "      <td>Degraded Wire Wire was abnormally degraded in ...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "      <td>['personal accountability', 'problem identific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Texas</td>\n",
       "      <td>The root cause for this event is that manageme...</td>\n",
       "      <td>['leadership safety values and actions', 'prob...</td>\n",
       "      <td>['effective safety communication', 'leadership...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Texas</td>\n",
       "      <td>The cause of the event was failure of the ECW ...</td>\n",
       "      <td>['problem identification and resolution']</td>\n",
       "      <td>['work processes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>South Texas</td>\n",
       "      <td>The root cause of the event was an inadequate ...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Diablo Canyon</td>\n",
       "      <td>The cause of the electrical fault could not be...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "      <td>['questioning attitude', 'work processes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Davis-Besse</td>\n",
       "      <td>The electrician checking the status of the loc...</td>\n",
       "      <td>['personal accountability', 'work processes']</td>\n",
       "      <td>['decision making', 'personal accountability',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Davis-Besse</td>\n",
       "      <td>The cause of this event was determined to be i...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "      <td>['decision making', 'effective safety communic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>South Texas</td>\n",
       "      <td>It was incorrectly understood that the compone...</td>\n",
       "      <td>['decision making', 'problem identification an...</td>\n",
       "      <td>['problem identification and resolution', 'wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Power Plant                                 Sentence/Paragraph  \\\n",
       "0   Diablo Canyon  Personnel error (cognitive) by a utility licen...   \n",
       "1   Diablo Canyon  The cause of the events was human error enable...   \n",
       "2   Diablo Canyon  Degraded Wire Wire was abnormally degraded in ...   \n",
       "3     South Texas  The root cause for this event is that manageme...   \n",
       "4     South Texas  The cause of the event was failure of the ECW ...   \n",
       "..            ...                                                ...   \n",
       "65    South Texas  The root cause of the event was an inadequate ...   \n",
       "66  Diablo Canyon  The cause of the electrical fault could not be...   \n",
       "67    Davis-Besse  The electrician checking the status of the loc...   \n",
       "68    Davis-Besse  The cause of this event was determined to be i...   \n",
       "69    South Texas  It was incorrectly understood that the compone...   \n",
       "\n",
       "                                     Predicted Labels  \\\n",
       "0       ['personal accountability', 'work processes']   \n",
       "1   ['continuous learning', 'personal accountabili...   \n",
       "2   ['problem identification and resolution', 'wor...   \n",
       "3   ['leadership safety values and actions', 'prob...   \n",
       "4           ['problem identification and resolution']   \n",
       "..                                                ...   \n",
       "65  ['problem identification and resolution', 'wor...   \n",
       "66  ['problem identification and resolution', 'wor...   \n",
       "67      ['personal accountability', 'work processes']   \n",
       "68  ['problem identification and resolution', 'wor...   \n",
       "69  ['decision making', 'problem identification an...   \n",
       "\n",
       "                                          True Labels  \n",
       "0   ['decision making', 'personal accountability',...  \n",
       "1   ['leadership safety values and actions', 'pers...  \n",
       "2   ['personal accountability', 'problem identific...  \n",
       "3   ['effective safety communication', 'leadership...  \n",
       "4                                  ['work processes']  \n",
       "..                                                ...  \n",
       "65  ['problem identification and resolution', 'wor...  \n",
       "66         ['questioning attitude', 'work processes']  \n",
       "67  ['decision making', 'personal accountability',...  \n",
       "68  ['decision making', 'effective safety communic...  \n",
       "69  ['problem identification and resolution', 'wor...  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Results on FewShotNoTuning</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test size: 70\n",
      "Average Accuracy on Test Data: 35.67 %\n",
      "Average Precision on Test Data: 50.24 %\n",
      "Average Recall on Test Data: 47.98 %\n",
      "Average F1-Score on Test Data: 47.01 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total test size: {len(df)}\")\n",
    "calculate_metrics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Specifically on Diablo Canyon</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test size (ONLY DIABLO CANYON): 31\n",
      "Average Accuracy on Test Data: 29.03 %\n",
      "Average Precision on Test Data: 42.47 %\n",
      "Average Recall on Test Data: 40.86 %\n",
      "Average F1-Score on Test Data: 39.68 %\n"
     ]
    }
   ],
   "source": [
    "diablo_canyon_df = df[df['Power Plant'] == 'Diablo Canyon']\n",
    "diablo_canyon_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Total test size (ONLY DIABLO CANYON): {len(diablo_canyon_df)}\")\n",
    "calculate_metrics(diablo_canyon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test size (ONLY SOUTH TEXAS): 27\n",
      "Average Accuracy on Test Data: 42.35 %\n",
      "Average Precision on Test Data: 55.56 %\n",
      "Average Recall on Test Data: 54.32 %\n",
      "Average F1-Score on Test Data: 53.23 %\n"
     ]
    }
   ],
   "source": [
    "south_texas_df = df[df['Power Plant'] == 'South Texas']\n",
    "south_texas_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Total test size (ONLY SOUTH TEXAS): {len(south_texas_df)}\")\n",
    "calculate_metrics(south_texas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test size (ONLY DAVIS-BESSE): 12\n",
      "Average Accuracy on Test Data: 37.78 %\n",
      "Average Precision on Test Data: 58.33 %\n",
      "Average Recall on Test Data: 52.08 %\n",
      "Average F1-Score on Test Data: 51.94 %\n"
     ]
    }
   ],
   "source": [
    "davis_df = df[df['Power Plant'] == 'Davis-Besse']\n",
    "davis_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Total test size (ONLY DAVIS-BESSE): {len(davis_df)}\")\n",
    "calculate_metrics(davis_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
